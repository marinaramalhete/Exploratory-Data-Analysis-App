## Plan: ModernizaÃ§Ã£o do Exploratory Data Analysis App

O projeto atual Ã© um app Streamlit de 2020, com 420 linhas em um Ãºnico arquivo, dependÃªncias desatualizadas (Streamlit 0.58, Pandas 1.0, NumPy 1.18), ~7 APIs removidas/deprecadas que impedem a execuÃ§Ã£o em versÃµes modernas, zero testes, zero type hints, e zero infraestrutura de engenharia. O objetivo Ã© transformÃ¡-lo em um app profissional multi-page com profiling automÃ¡tico, suporte a mÃºltiplos formatos, export de grÃ¡ficos â€” mantendo Plotly + Seaborn â€” usando pip + requirements.txt e deploy no Streamlit Cloud.

---

### Fase 0 â€” Setup local e validaÃ§Ã£o do estado atual

1. Criar o ambiente conda `eda-app` com Python 3.11+ e instalar as dependÃªncias atuais do [requirements.txt](Exploratory-Data-Analysis-App/requirements.txt)
2. Rodar `streamlit run eda_main.py` e documentar todos os erros e warnings (esperamos falhas por `np.object`, `st.cache`, `sns.distplot`, etc.)
3. Commit do estado original como baseline (tag `v0-legacy`)

### Fase 1 â€” AtualizaÃ§Ã£o de dependÃªncias e correÃ§Ã£o de breaking changes

4. Reduzir o [requirements.txt](Exploratory-Data-Analysis-App/requirements.txt) de 80 pacotes para as ~10 dependÃªncias diretas reais (o arquivo atual Ã© um `pip freeze` que inclui boto3, jupyter, pywinpty, etc. â€” nada a ver com o app)
5. Atualizar para versÃµes modernas: `streamlit>=1.40`, `pandas>=2.2`, `numpy>=2.1`, `seaborn>=0.13`, `plotly>=5.24`, `matplotlib>=3.9`, `scipy>=1.14`
6. Corrigir todas as APIs removidas/deprecadas em [eda_main.py](Exploratory-Data-Analysis-App/eda_main.py):
   - `np.object` â†’ `"object"` (string) â€” 5 ocorrÃªncias nas linhas 21, 89, 91, 345, 393
   - `st.cache` â†’ `st.cache_data` â€” 8 ocorrÃªncias; remover `allow_output_mutation`
   - `sns.distplot` â†’ `sns.histplot(..., kde=True)` â€” linha 80
   - `df.fillna(method='ffill'/'bfill')` â†’ `df.ffill()` / `df.bfill()` â€” linhas 110, 113
   - `st.pyplot()` sem argumentos â†’ `st.pyplot(fig)` â€” 6 ocorrÃªncias
   - `df.corr()` â†’ `df.select_dtypes('number').corr()` â€” linha 70
   - Duplicate `key` nos widgets `selectbox` â†’ keys Ãºnicos â€” linhas 224-226, 231-233, 300-303
7. Rodar o app novamente e confirmar que todas as funcionalidades existentes funcionam sem erros
8. Commit: `fix: update all dependencies and fix deprecated APIs`

### Fase 2 â€” ReestruturaÃ§Ã£o do cÃ³digo (engenharia)

9. Criar estrutura modular de projeto com `src/` layout:
   ```
   src/eda_app/
   â”œâ”€â”€ __init__.py
   â”œâ”€â”€ app.py                  # Entry point (main)
   â”œâ”€â”€ data/
   â”‚   â”œâ”€â”€ loader.py           # get_data, parse CSV/Excel/Parquet
   â”‚   â””â”€â”€ preprocessing.py    # input_null, input_null_cat, transforms
   â”œâ”€â”€ stats/
   â”‚   â”œâ”€â”€ descriptive.py      # pd_of_stats, pf_of_info, pd_of_stats_quantile, get_stats, get_info
   â”‚   â””â”€â”€ correlation.py      # Corr, heatmap_vars
   â”œâ”€â”€ visualization/
   â”‚   â”œâ”€â”€ plots.py            # Classe EDA refatorada (mÃ©todos de grÃ¡fico)
   â”‚   â”œâ”€â”€ univariate.py       # plot_univariate
   â”‚   â””â”€â”€ multivariate.py     # plot_multivariate
   â””â”€â”€ components/
       â”œâ”€â”€ sidebar.py          # LÃ³gica da sidebar
       â””â”€â”€ download.py         # Export de grÃ¡ficos e dados
   pages/
   â”œâ”€â”€ 1_ðŸ“Š_Overview.py
   â”œâ”€â”€ 2_ðŸ“ˆ_Univariate.py
   â”œâ”€â”€ 3_ðŸ“‰_Multivariate.py
   â””â”€â”€ 4_ðŸ“‹_Profiling.py
   ```
10. Adicionar type hints em todas as funÃ§Ãµes e classes
11. Adicionar docstrings (Google style) em todas as funÃ§Ãµes e classes
12. Corrigir naming inconsistente: `CountPlot` â†’ `count_plot`, `DistPlot` â†’ `dist_plot`, `Corr` â†’ `correlation_heatmap`, `pf_of_info` â†’ `variable_info`, `pd_of_stats` â†’ `descriptive_stats`
13. Substituir os if-chains longos em `plot_multivariate` por dispatch dict ou match/case
14. Mover funÃ§Ãµes `pretty()` e `map_func()` de dentro de `plot_multivariate` para nÃ­vel de mÃ³dulo
15. Substituir `type(col) != list` por `isinstance(col, list)` â€” linhas 122, 137
16. Remover backslash line continuations â†’ usar parÃªnteses
17. Adicionar `st.set_page_config()` como primeiro comando Streamlit (tÃ­tulo, favicon, wide layout)
18. Implementar `st.session_state` para persistir transformaÃ§Ãµes de dados entre reruns (ex.: imputaÃ§Ã£o de nulos)
19. Adicionar tratamento de erros robusto: try/except em uploads, parsing, operaÃ§Ãµes de dados; mensagens amigÃ¡veis via `st.error()`
20. Commit: `refactor: modular architecture with type hints and docstrings`

### Fase 3 â€” Novas funcionalidades

21. **Multi-page app**: Converter para Streamlit multi-page nativo (pasta `pages/`) com 4 pÃ¡ginas:
    - **Overview** â€” Upload, info bÃ¡sica, preview dos dados, missing values
    - **Univariate** â€” AnÃ¡lise de uma variÃ¡vel
    - **Multivariate** â€” AnÃ¡lise multivariada com todos os grÃ¡ficos
    - **Profiling** â€” RelatÃ³rio automÃ¡tico completo
22. **Profiling automÃ¡tico**: Ao subir o CSV, gerar um relatÃ³rio estilo ydata-profiling com:
    - DistribuiÃ§Ã£o de cada variÃ¡vel (histograma + stats)
    - Matriz de correlaÃ§Ã£o
    - DetecÃ§Ã£o de outliers (IQR e Z-score)
    - Alertas automÃ¡ticos (alta cardinalidade, muitos NaN, colunas constantes, alta correlaÃ§Ã£o entre features)
    - Amostra dos dados
23. **Suporte a Excel e Parquet**: Aceitar `.xlsx` e `.parquet` alÃ©m de `.csv` no uploader; adicionar `openpyxl` e `pyarrow` nas dependÃªncias
24. **Export de grÃ¡ficos**: BotÃ£o de download em PNG/SVG para cada grÃ¡fico gerado:
    - Plotly: usar `fig.to_image()` (requer `kaleido`)
    - Seaborn/Matplotlib: usar `fig.savefig()` em buffer BytesIO
    - Exibir via `st.download_button()`
25. Substituir `get_table_download_link` (base64 hack) por `st.download_button()` nativo para export de dados
26. Adicionar componentes visuais modernos: `st.tabs()`, `st.columns()`, `st.expander()`, `st.metric()` para exibir KPIs
27. Commit: `feat: multi-page app, auto-profiling, Excel/Parquet support, chart export`

### Fase 4 â€” Infraestrutura e qualidade

28. Criar `pyproject.toml` com metadata do projeto, configuraÃ§Ã£o do ruff, pytest, e mypy
29. Configurar **ruff** para linting + formatting (substituindo black/flake8/isort)
30. Criar `.pre-commit-config.yaml` com hooks: ruff, mypy, trailing-whitespace, check-yaml
31. Escrever testes com **pytest**:
    - `tests/test_loader.py` â€” testa carregamento de CSV, Excel, Parquet, arquivos invÃ¡lidos
    - `tests/test_stats.py` â€” testa funÃ§Ãµes de estatÃ­stica descritiva, quantis, correlaÃ§Ã£o
    - `tests/test_preprocessing.py` â€” testa imputaÃ§Ã£o de nulos
    - `tests/test_visualization.py` â€” testa que grÃ¡ficos sÃ£o gerados sem erros (smoke tests)
32. Criar **GitHub Actions** CI pipeline (`.github/workflows/ci.yml`):
    - Run ruff lint + format check
    - Run mypy
    - Run pytest
    - Trigger on push/PR
33. Atualizar `.gitignore` com: `__pycache__/`, `*.pyc`, `.env`, `.venv/`, `.ruff_cache/`, `.mypy_cache/`, `.pytest_cache/`, `*.egg-info/`, `.streamlit/secrets.toml`
34. Criar `.streamlit/config.toml` versionado no repo (substituindo o gerado por `setup.sh`)
35. Remover `setup.sh` e `Procfile` (desnecessÃ¡rios para Streamlit Cloud)
36. Commit: `chore: add pyproject.toml, CI, pre-commit, tests, ruff`

### Fase 5 â€” Polish e deploy

37. Reescrever o [README.md](Exploratory-Data-Analysis-App/README.md) com:
    - Badges (CI status, Python version, Streamlit)
    - Screenshots/GIFs do app
    - InstruÃ§Ãµes de setup local com `pip install -r requirements.txt`
    - Link para o app no Streamlit Cloud
    - SeÃ§Ã£o "Architecture" explicando a estrutura modular
38. Configurar deploy no **Streamlit Cloud** (conectar repo GitHub, definir entry point `src/eda_app/app.py`)
39. Rodar o app end-to-end com datasets reais (Titanic, Iris, housing) e validar todas as funcionalidades
40. Tag `v1.0.0` â€” release

---

### VerificaÃ§Ã£o

- **Fase 0**: App roda (ou falha com erros documentados) no ambiente conda
- **Fase 1**: `streamlit run eda_main.py` funciona sem erros/warnings com dependÃªncias modernas
- **Fase 2**: `ruff check src/` passa; `mypy src/` sem erros; todas as funcionalidades existentes ainda funcionam
- **Fase 3**: Upload de CSV/Excel/Parquet funciona; profiling gera relatÃ³rio; grÃ¡ficos exportam; multi-page navega corretamente
- **Fase 4**: `pytest` passa; `pre-commit run --all-files` passa; GitHub Actions CI verde
- **Fase 5**: App acessÃ­vel no Streamlit Cloud; README renderiza corretamente

### DecisÃµes

- **Deploy**: Streamlit Cloud (gratuito, nativo, elimina setup.sh/Procfile)
- **DependÃªncias**: pip + requirements.txt (simples, sem overhead de ferramenta extra)
- **GrÃ¡ficos**: Manter Plotly + Seaborn/Matplotlib (aproveitar o melhor de cada)
- **Profiling**: ImplementaÃ§Ã£o prÃ³pria (nÃ£o usar ydata-profiling como dependÃªncia â€” mais leve e customizÃ¡vel, mostra habilidade de engenharia)
- **Python**: 3.11+ (melhor performance, type hints modernos, match/case disponÃ­vel)
- **Linting**: ruff (substitui black + flake8 + isort em uma ferramenta sÃ³)
